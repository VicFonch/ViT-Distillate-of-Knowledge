{"cells":[{"cell_type":"markdown","metadata":{"id":"Po2elYLBHPKz"},"source":["# ***Tarea 3***\n","## Asignatura: Transformer y Diffusers\n","\n","#### Autor: Victor M. Fonte Chavez\n","\n","#### Ejercicio 2: Destilar el conocimiento del Vision Transformer (ViT)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":158,"status":"ok","timestamp":1699855135763,"user":{"displayName":"Victor Manuel Fonte Chavez","userId":"11502212207063866761"},"user_tz":360},"id":"XUrfDnY2HPK2"},"outputs":[],"source":["import os\n","import json\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from collections import defaultdict\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","torch.set_float32_matmul_precision('medium')\n","\n","import torchvision as tv\n","from torchvision import transforms\n","from torchvision.datasets import ImageFolder\n","from torch.utils.data import DataLoader\n","\n","from torchmetrics import MetricCollection\n","from torchmetrics.classification.accuracy import Accuracy\n","from torchmetrics.classification.stat_scores import StatScores\n","\n","from transformers import ViTForImageClassification, DeiTForImageClassification\n","\n","import lightning as pl"]},{"cell_type":"markdown","metadata":{},"source":["### Trainer Class: Comun para todos los ejercicios"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["class TrainerFineTune(pl.LightningModule):\n","    def __init__(self, model, save_dir = None):\n","        super(TrainerFineTune, self).__init__()\n","\n","        self.n_classes = 102\n","        \n","        self.net = model\n","        for name, param in self.net.named_parameters():\n","            if \"classifier\" not in name:\n","                param.requires_grad = False\n","        \n","        self.save_dir = save_dir\n","\n","        self.train_metrics = MetricCollection(\n","            {\n","                \"train_acc\": Accuracy(num_classes=self.n_classes, task=\"multiclass\", top_k=1),\n","                \"train_acc_top5\": Accuracy(\n","                    num_classes=self.n_classes,\n","                    task=\"multiclass\",\n","                    top_k=min(5, self.n_classes),\n","                ),\n","            }\n","        )\n","        self.val_metrics = MetricCollection(\n","            {\n","                \"val_acc\": Accuracy(num_classes=self.n_classes, task=\"multiclass\", top_k=1),\n","                \"val_acc_top5\": Accuracy(\n","                    num_classes=self.n_classes,\n","                    task=\"multiclass\",\n","                    top_k=min(5, self.n_classes),\n","                ),\n","            }\n","        )\n","        self.train_progress = {\"loss\": [], \"acc\": []}\n","        self.val_progress = {\"loss\": [], \"acc\": []}\n","        self.train_loss = []\n","        self.train_acc = []\n","        self.val_loss = []\n","        self.val_acc = []\n","\n","    def forward(self, x):\n","        x = self.net(x).logits\n","        return x\n","\n","    def training_step(self, batch, _):\n","        images, y = batch\n","        y = F.one_hot(y, num_classes=self.n_classes).float()\n","\n","        y_hat = self.forward(images)\n","        loss = F.cross_entropy(y_hat, y.argmax(1))\n","        mets = self.train_metrics(y_hat, y.argmax(1))\n","\n","        self.train_progress[\"loss\"].append(loss.item())\n","        self.train_progress[\"acc\"].append(100*mets[\"train_acc\"].item())\n","\n","        self.log(\"lr\", self.trainer.optimizers[0].param_groups[0][\"lr\"], prog_bar=True)\n","        self.log(\"train_loss\", loss, prog_bar=True, on_step=True, on_epoch=False, sync_dist=True)\n","        with torch.inference_mode():\n","            for k, v in mets.items():\n","                self.log(k, 100*v, prog_bar=True, on_step=True, on_epoch=False, sync_dist=True)\n","\n","        return loss\n","\n","    @torch.no_grad()\n","    def validation_step(self, batch, _):\n","        images, y = batch\n","        y = F.one_hot(y, num_classes=self.n_classes).float()\n","\n","        y_hat = self.forward(images)\n","        loss = F.cross_entropy(y_hat, y.argmax(1))\n","        mets = self.val_metrics(y_hat, y.argmax(1))\n","\n","        self.val_progress[\"loss\"].append(loss.item())\n","        self.val_progress[\"acc\"].append(100*mets[\"val_acc\"].item())\n","\n","        self.log(\"val_loss\", loss, prog_bar=True, on_step=False, on_epoch=True, sync_dist=True)\n","        for k, v in mets.items():\n","            self.log(k, 100*v, prog_bar=True, on_step=False, on_epoch=True, sync_dist=True)\n","\n","    @torch.no_grad()\n","    def on_train_epoch_end(self):\n","        self.train_loss.append(np.mean(self.train_progress[\"loss\"]))\n","        self.val_loss.append(np.mean(self.val_progress[\"loss\"]))\n","        self.train_acc.append(np.mean(self.train_progress[\"acc\"]))\n","        self.val_acc.append(np.mean(self.val_progress[\"acc\"]))\n","\n","        self.train_progress[\"loss\"].clear()\n","        self.val_progress[\"loss\"].clear()\n","        self.train_progress[\"acc\"].clear()\n","        self.val_progress[\"acc\"].clear()\n","\n","        print(f\"\\nEpoch {self.current_epoch+1}/{self.trainer.max_epochs}\", f\"val_loss: {self.val_loss[-1]:.4f}\", f\"val_acc: {self.val_acc[-1]:.4f}\")\n","\n","        if self.save_dir is not None:\n","            torch.save(self.net, os.path.join(self.save_dir, f\"model_{self.current_epoch}.ckpt\"))\n","\n","    def configure_optimizers(self):\n","        optimizer = optim.Adam(self.net.parameters())\n","        scheduler = CosineAnnealingLR(\n","                    optimizer,\n","                    T_max=410,\n","                    eta_min=5e-5\n","                )\n","\n","        return {\n","            \"optimizer\": optimizer,\n","            \"lr_scheduler\": {\n","                \"scheduler\": scheduler,\n","                \"interval\": \"step\",\n","                \"frequency\": 1,\n","            }\n","        }"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["class TrainerDistillation(pl.LightningModule):\n","    def __init__(self, teacher, student, save_dir = None, alpha = 0.25, tau = 2):\n","        \n","        super(TrainerDistillation, self).__init__()\n","\n","        self.n_classes = 102\n","\n","        self.teacher = teacher.eval().requires_grad_(False)\n","        self.student = student\n","        self.freeze_gradients(self.student)\n","        \n","        self.save_dir = save_dir\n","        self.alpha = alpha\n","        self.tau = tau\n","\n","        self.train_metrics = MetricCollection(\n","            {\n","                \"train_acc\": Accuracy(num_classes=self.n_classes, task=\"multiclass\", top_k=1),\n","                \"train_acc_top5\": Accuracy(\n","                    num_classes=self.n_classes,\n","                    task=\"multiclass\",\n","                    top_k=min(5, self.n_classes),\n","                ),\n","            }\n","        )\n","        self.val_metrics = MetricCollection(\n","            {\n","                \"val_acc\": Accuracy(num_classes=self.n_classes, task=\"multiclass\", top_k=1),\n","                \"val_acc_top5\": Accuracy(\n","                    num_classes=self.n_classes,\n","                    task=\"multiclass\",\n","                    top_k=min(5, self.n_classes),\n","                ),\n","            }\n","        )\n","        self.train_progress = {\"loss\": [], \"acc\": []}\n","        self.val_progress = {\"loss\": [], \"acc\": []}\n","        self.train_loss = []\n","        self.train_acc = []\n","        self.val_loss = []\n","        self.val_acc = []\n","    \n","    def freeze_gradients(self, net):\n","        for name, param in net.named_parameters():\n","            if \"classifier\" not in name:\n","                param.requires_grad = False\n","\n","    def student_loss(self, y, y_hat):\n","        return F.cross_entropy(y_hat, y)\n","\n","    def distillation_loss(self, student_logits, teacher_logits):\n","        soft_targets = F.softmax(teacher_logits/self.tau, dim=1)\n","        soft_prob = F.log_softmax(student_logits/self.tau, dim=1)\n","        return -torch.sum(soft_targets * soft_prob) / soft_prob.size()[0] * (self.tau**2)\n","\n","    def forward(self, x, choice = \"teacher\"):\n","        if choice == \"teacher\":\n","            return self.teacher(x).logits\n","        else:\n","            return self.student(x).logits\n","\n","    def training_step(self, batch, _):\n","        images, y = batch\n","        y = F.one_hot(y, num_classes=self.n_classes).float()\n","        \n","        teacher_pred = self.forward(images, \"teacher\")\n","        student_pred = self.forward(images, \"student\")\n","\n","        student_loss = self.student_loss(y, student_pred)\n","        distillation_loss = self.distillation_loss(student_pred, teacher_pred)\n","        loss = (1 - self.alpha) * student_loss + self.alpha * distillation_loss\n","\n","        mets = self.train_metrics(student_pred, y.argmax(1))\n","\n","        self.train_progress[\"loss\"].append(loss.item())\n","        self.train_progress[\"acc\"].append(100*mets[\"train_acc\"].item())\n","\n","        self.log(\"lr\", self.trainer.optimizers[0].param_groups[0][\"lr\"], prog_bar=True)\n","        self.log(\"train_student_loss\", student_loss, prog_bar=True, on_step=True, on_epoch=False, sync_dist=True)\n","        self.log(\"train_distillation_loss\", distillation_loss, prog_bar=True, on_step=True, on_epoch=False, sync_dist=True)\n","        self.log(\"train_loss\", loss, prog_bar=True, on_step=True, on_epoch=False, sync_dist=True)\n","        with torch.inference_mode():\n","            for k, v in mets.items():\n","                self.log(k, 100*v, prog_bar=True, on_step=True, on_epoch=False, sync_dist=True)\n","\n","        return loss\n","\n","    @torch.no_grad()\n","    def validation_step(self, batch, _):\n","        images, y = batch\n","        y = F.one_hot(y, num_classes=self.n_classes).float()\n","\n","        teacher_pred = self.forward(images, \"teacher\")\n","        student_pred = self.forward(images, \"student\")\n","\n","        student_loss = self.student_loss(y, student_pred)\n","        distillation_loss = self.distillation_loss(student_pred, teacher_pred)\n","        loss = (1 - self.alpha) * student_loss + self.alpha * distillation_loss\n","\n","        mets = self.val_metrics(student_pred, y.argmax(1))\n","\n","        self.val_progress[\"loss\"].append(loss.item())\n","        self.val_progress[\"acc\"].append(100*mets[\"val_acc\"].item())\n","        \n","        self.log(\"val_student_loss\", student_loss, prog_bar=True, on_step=False, on_epoch=True, sync_dist=True)\n","        self.log(\"val_distillation_loss\", distillation_loss, prog_bar=True, on_step=False, on_epoch=True, sync_dist=True)\n","        self.log(\"val_loss\", loss, prog_bar=True, on_step=False, on_epoch=True, sync_dist=True)\n","        for k, v in mets.items():\n","            self.log(k, 100*v, prog_bar=True, on_step=False, on_epoch=True, sync_dist=True)\n","\n","    @torch.no_grad()\n","    def on_train_epoch_end(self):\n","        self.train_loss.append(np.mean(self.train_progress[\"loss\"]))\n","        self.val_loss.append(np.mean(self.val_progress[\"loss\"]))\n","        self.train_acc.append(np.mean(self.train_progress[\"acc\"]))\n","        self.val_acc.append(np.mean(self.val_progress[\"acc\"]))\n","\n","        self.train_progress[\"loss\"].clear()\n","        self.val_progress[\"loss\"].clear()\n","        self.train_progress[\"acc\"].clear()\n","        self.val_progress[\"acc\"].clear()\n","\n","        print(f\"\\nEpoch {self.current_epoch+1}/{self.trainer.max_epochs}\", \\\n","              f\"val_loss: {self.val_loss[-1]:.4f}\", f\"val_acc: {self.val_acc[-1]:.4f}\")\n","\n","        if self.save_dir is not None:\n","            torch.save(self.student, os.path.join(self.save_dir, f\"model_{self.current_epoch}.ckpt\"))\n","\n","    def configure_optimizers(self):\n","        optimizer = optim.Adam(self.student.parameters())\n","        scheduler = CosineAnnealingLR(\n","                    optimizer,\n","                    T_max=410,\n","                    eta_min=5e-5\n","                )\n","\n","        return {\n","            \"optimizer\": optimizer,\n","            \"lr_scheduler\": {\n","                \"scheduler\": scheduler,\n","                \"interval\": \"step\",\n","                \"frequency\": 1,\n","            }\n","        }\n"]},{"cell_type":"markdown","metadata":{"id":"18sXPNtSHPK3"},"source":["### Cargado de los datos"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":141,"status":"ok","timestamp":1699853859238,"user":{"displayName":"Victor Manuel Fonte Chavez","userId":"11502212207063866761"},"user_tz":360},"id":"7e9XqVBHHPK4"},"outputs":[],"source":["data_dir = \"./_data\"\n","train_dir = os.path.join(data_dir, \"train\")\n","valid_dir = os.path.join(data_dir, \"valid\")\n","\n","cat_to_name_file = os.path.join(data_dir, 'cat_to_name.json')\n","\n","with open(cat_to_name_file, 'r') as f:\n","    cat_to_name = json.load(f)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":376,"status":"ok","timestamp":1699853972610,"user":{"displayName":"Victor Manuel Fonte Chavez","userId":"11502212207063866761"},"user_tz":360},"id":"5Yp8Zfi-HPK4"},"outputs":[],"source":["size = 224\n","min_scale = 0.08\n","max_scale = 1.0\n","flip_prob = 0.5\n","rand_aug_n = 0\n","rand_aug_m = 9\n","mean = (0.5, 0.5, 0.5)\n","std = (0.5, 0.5, 0.5)\n","\n","batch_size = 32\n","n_classes = len(os.listdir(train_dir))\n","\n","transforms_train = transforms.Compose(\n","    [\n","        transforms.RandomResizedCrop(\n","            (size, size),\n","            scale=(min_scale, max_scale),\n","        ),\n","        transforms.RandomHorizontalFlip(flip_prob),\n","        transforms.RandAugment(rand_aug_n, rand_aug_m),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=mean, std=std),\n","    ]\n",")\n","transforms_val = transforms.Compose(\n","    [\n","        transforms.Resize(\n","            (size, size),\n","        ),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=mean, std=std),\n","    ]\n",")\n","\n","train_dataset = ImageFolder(root=train_dir, transform=transforms_train)\n","valid_dataset = ImageFolder(root=valid_dir, transform=transforms_val)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"eypIL9_bHPK3"},"source":["Tomo un modelo Destilado de ViT y realizo finetune sobre el conjunto de datos de Flowers102. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":746,"referenced_widgets":["69b2375161a74dc2bbe6e5577b9f4cda","7fe6cbf186f94d57a68253c1706f2580","6b8edf26a2fa4166b1ba23018c949dda","103ec964c7bb43cdadc57009c0537ef9","59a77a6345524dcf941c70967bfc9a2d","a93d0b0ab66f4b20a119572d9d710612","02cd0144f9844747aa65d0e9d6f2b3fb","7b62d8e70d1840cea2c8e56ddc182ab0","61aafa86423543f688b7c6c5198523d7","99d377b675d7464e95ce27dd01c9ba41","8aa6e33847e043a59c67786fc99ec25a","369bea5e2cfb48228b37c00beac9504b","bab01974cea44d80b8e237d74d77a222","0bc55420944240619ea526578924072f","a4d0f2fd487a468eaab129a1ea702db5","c7db01aa60534c4e958668d78ce8aefb","578278203b3c456fb8265694876ad0c3","25516d0870b94962acb5b2bb807b55a7","945d974d5ea543bf84895b5147e617ed","c093d9c835874013a7752d3c1c49e759","f7610b7b3b6348699abc461fa7847aed","4da79c41190246b4a95605a48e5fc95f"]},"executionInfo":{"elapsed":236954,"status":"ok","timestamp":1699853693960,"user":{"displayName":"Victor Manuel Fonte Chavez","userId":"11502212207063866761"},"user_tz":360},"id":"ajGuOkjIHPK6","outputId":"2bce7b0c-1b50-464a-ad9a-a1dced45373e"},"outputs":[{"name":"stderr","output_type":"stream","text":["GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","Some weights of DeiTForImageClassification were not initialized from the model checkpoint at facebook/deit-base-distilled-patch16-224 and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name          | Type                       | Params\n","-------------------------------------------------------------\n","0 | net           | DeiTForImageClassification | 85.9 M\n","1 | train_metrics | MetricCollection           | 0     \n","2 | val_metrics   | MetricCollection           | 0     \n","-------------------------------------------------------------\n","78.4 K    Trainable params\n","85.8 M    Non-trainable params\n","85.9 M    Total params\n","343.515   Total estimated model params size (MB)\n"]},{"name":"stdout","output_type":"stream","text":["Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\vfont\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  rank_zero_warn(\n"]},{"name":"stdout","output_type":"stream","text":["                                                                           "]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\vfont\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  rank_zero_warn(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 0: 100%|██████████| 205/205 [01:26<00:00,  2.37it/s, v_num=54, lr=0.000529, train_loss=1.200, train_acc=79.20, train_acc_top5=95.80, val_loss=1.300, val_acc=80.60, val_acc_top5=96.20]\n","Epoch 1/10 val_loss: 1.5360 val_acc: 75.0248\n","Epoch 1: 100%|██████████| 205/205 [01:46<00:00,  1.92it/s, v_num=54, lr=5e-5, train_loss=0.835, train_acc=95.80, train_acc_top5=95.80, val_loss=1.050, val_acc=85.50, val_acc_top5=97.60]    \n","Epoch 2/10 val_loss: 1.0465 val_acc: 85.6036\n","Epoch 2: 100%|██████████| 205/205 [02:01<00:00,  1.69it/s, v_num=54, lr=0.000521, train_loss=1.070, train_acc=79.20, train_acc_top5=95.80, val_loss=0.899, val_acc=85.90, val_acc_top5=98.00]\n","Epoch 3/10 val_loss: 0.8981 val_acc: 85.9909\n","Epoch 3: 100%|██████████| 205/205 [01:46<00:00,  1.92it/s, v_num=54, lr=0.001, train_loss=0.596, train_acc=87.50, train_acc_top5=100.0, val_loss=0.597, val_acc=89.90, val_acc_top5=98.50]   \n","Epoch 4/10 val_loss: 0.5960 val_acc: 89.9306\n","Epoch 4: 100%|██████████| 205/205 [01:56<00:00,  1.76it/s, v_num=54, lr=0.000529, train_loss=0.533, train_acc=83.30, train_acc_top5=95.80, val_loss=0.462, val_acc=92.10, val_acc_top5=98.50]\n","Epoch 5/10 val_loss: 0.4602 val_acc: 92.0940\n","Epoch 5: 100%|██████████| 205/205 [01:51<00:00,  1.85it/s, v_num=54, lr=5e-5, train_loss=0.270, train_acc=95.80, train_acc_top5=100.0, val_loss=0.433, val_acc=92.80, val_acc_top5=98.50]    \n","Epoch 6/10 val_loss: 0.4317 val_acc: 92.8152\n","Epoch 6: 100%|██████████| 205/205 [02:00<00:00,  1.70it/s, v_num=54, lr=0.000521, train_loss=0.406, train_acc=91.70, train_acc_top5=100.0, val_loss=0.414, val_acc=92.40, val_acc_top5=98.80]\n","Epoch 7/10 val_loss: 0.4129 val_acc: 92.4546\n","Epoch 7: 100%|██████████| 205/205 [01:55<00:00,  1.78it/s, v_num=54, lr=0.001, train_loss=0.132, train_acc=100.0, train_acc_top5=100.0, val_loss=0.374, val_acc=92.40, val_acc_top5=98.90]    \n","Epoch 8/10 val_loss: 0.3717 val_acc: 92.4546\n","Epoch 8: 100%|██████████| 205/205 [01:58<00:00,  1.73it/s, v_num=54, lr=0.000529, train_loss=0.184, train_acc=100.0, train_acc_top5=100.0, val_loss=0.325, val_acc=94.00, val_acc_top5=99.10]\n","Epoch 9/10 val_loss: 0.3234 val_acc: 94.0171\n","Epoch 9: 100%|██████████| 205/205 [01:58<00:00,  1.72it/s, v_num=54, lr=5e-5, train_loss=0.227, train_acc=100.0, train_acc_top5=100.0, val_loss=0.314, val_acc=94.00, val_acc_top5=98.70]     \n","Epoch 10/10 val_loss: 0.3126 val_acc: 94.0171\n"]},{"name":"stderr","output_type":"stream","text":["`Trainer.fit` stopped: `max_epochs=10` reached.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9: 100%|██████████| 205/205 [02:02<00:00,  1.67it/s, v_num=54, lr=5e-5, train_loss=0.227, train_acc=100.0, train_acc_top5=100.0, val_loss=0.314, val_acc=94.00, val_acc_top5=98.70]\n"]}],"source":["distilled_vit = DeiTForImageClassification.from_pretrained('facebook/deit-base-distilled-patch16-224', num_labels=102)\n","model_trainer = TrainerFineTune(distilled_vit)\n","\n","trainer = pl.Trainer(\n","    max_epochs = 10,\n","    devices=1,\n","    accelerator='gpu',\n",")\n","trainer.fit(model_trainer, train_dataloader, valid_dataloader)"]},{"cell_type":"markdown","metadata":{"id":"14ygdg3AHPK6"},"source":["Tomo un modelo ViT y destilo el conocimiento del ViT entrenado anteriormente. "]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of DeiTForImageClassification were not initialized from the model checkpoint at facebook/deit-base-distilled-patch16-224 and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name          | Type                       | Params\n","-------------------------------------------------------------\n","0 | teacher       | ViTForImageClassification  | 85.9 M\n","1 | student       | DeiTForImageClassification | 85.9 M\n","2 | train_metrics | MetricCollection           | 0     \n","3 | val_metrics   | MetricCollection           | 0     \n","-------------------------------------------------------------\n","78.4 K    Trainable params\n","171 M     Non-trainable params\n","171 M     Total params\n","687.023   Total estimated model params size (MB)\n"]},{"name":"stdout","output_type":"stream","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\vfont\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  rank_zero_warn(\n"]},{"name":"stdout","output_type":"stream","text":["                                                                           "]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\vfont\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  rank_zero_warn(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 0: 100%|██████████| 205/205 [02:35<00:00,  1.31it/s, v_num=55, lr=0.000529, train_student_loss=1.060, train_distillation_loss=19.50, train_loss=5.660, train_acc=95.80, train_acc_top5=100.0, val_student_loss=1.430, val_distillation_loss=19.40, val_loss=5.910, val_acc=81.50, val_acc_top5=96.70]\n","Epoch 1/10 val_loss: 6.0768 val_acc: 76.0293\n","Epoch 1: 100%|██████████| 205/205 [02:44<00:00,  1.25it/s, v_num=55, lr=5e-5, train_student_loss=1.340, train_distillation_loss=19.50, train_loss=5.890, train_acc=83.30, train_acc_top5=91.70, val_student_loss=1.220, val_distillation_loss=19.50, val_loss=5.780, val_acc=87.00, val_acc_top5=97.70]    \n","Epoch 2/10 val_loss: 5.7744 val_acc: 87.1661\n","Epoch 2: 100%|██████████| 205/205 [02:51<00:00,  1.19it/s, v_num=55, lr=0.000521, train_student_loss=1.130, train_distillation_loss=19.70, train_loss=5.790, train_acc=83.30, train_acc_top5=91.70, val_student_loss=1.100, val_distillation_loss=19.50, val_loss=5.710, val_acc=87.40, val_acc_top5=98.20]\n","Epoch 3/10 val_loss: 5.7138 val_acc: 87.5267\n","Epoch 3: 100%|██████████| 205/205 [1:07:12<00:00, 19.67s/it, v_num=55, lr=0.001, train_student_loss=0.819, train_distillation_loss=19.70, train_loss=5.550, train_acc=91.70, train_acc_top5=100.0, val_student_loss=0.854, val_distillation_loss=19.70, val_loss=5.560, val_acc=91.00, val_acc_top5=98.30]      \n","Epoch 4/10 val_loss: 5.5604 val_acc: 91.0123\n","Epoch 4: 100%|██████████| 205/205 [02:07<00:00,  1.61it/s, v_num=55, lr=0.000529, train_student_loss=0.695, train_distillation_loss=19.70, train_loss=5.440, train_acc=95.80, train_acc_top5=95.80, val_student_loss=0.746, val_distillation_loss=19.70, val_loss=5.480, val_acc=93.80, val_acc_top5=98.80]\n","Epoch 5/10 val_loss: 5.4798 val_acc: 93.7767\n","Epoch 5: 100%|██████████| 205/205 [02:07<00:00,  1.60it/s, v_num=55, lr=5e-5, train_student_loss=0.910, train_distillation_loss=19.50, train_loss=5.570, train_acc=79.20, train_acc_top5=100.0, val_student_loss=0.720, val_distillation_loss=19.70, val_loss=5.460, val_acc=93.40, val_acc_top5=98.70]    \n","Epoch 6/10 val_loss: 5.4576 val_acc: 93.4161\n","Epoch 6: 100%|██████████| 205/205 [02:08<00:00,  1.59it/s, v_num=55, lr=0.000521, train_student_loss=0.413, train_distillation_loss=19.70, train_loss=5.240, train_acc=100.0, train_acc_top5=100.0, val_student_loss=0.709, val_distillation_loss=19.70, val_loss=5.450, val_acc=93.30, val_acc_top5=98.80]\n","Epoch 7/10 val_loss: 5.4518 val_acc: 93.2959\n","Epoch 7: 100%|██████████| 205/205 [02:11<00:00,  1.56it/s, v_num=55, lr=0.001, train_student_loss=0.515, train_distillation_loss=19.80, train_loss=5.340, train_acc=100.0, train_acc_top5=100.0, val_student_loss=0.669, val_distillation_loss=19.70, val_loss=5.430, val_acc=94.10, val_acc_top5=99.10]   \n","Epoch 8/10 val_loss: 5.4256 val_acc: 94.1373\n","Epoch 8: 100%|██████████| 205/205 [02:11<00:00,  1.56it/s, v_num=55, lr=0.000529, train_student_loss=0.883, train_distillation_loss=19.70, train_loss=5.590, train_acc=83.30, train_acc_top5=95.80, val_student_loss=0.639, val_distillation_loss=19.70, val_loss=5.400, val_acc=94.10, val_acc_top5=99.10]\n","Epoch 9/10 val_loss: 5.4001 val_acc: 94.1373\n","Epoch 9: 100%|██████████| 205/205 [02:09<00:00,  1.59it/s, v_num=55, lr=5e-5, train_student_loss=0.492, train_distillation_loss=19.70, train_loss=5.310, train_acc=95.80, train_acc_top5=100.0, val_student_loss=0.632, val_distillation_loss=19.70, val_loss=5.390, val_acc=94.50, val_acc_top5=99.10]    \n","Epoch 10/10 val_loss: 5.3882 val_acc: 94.4979\n"]},{"name":"stderr","output_type":"stream","text":["`Trainer.fit` stopped: `max_epochs=10` reached.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9: 100%|██████████| 205/205 [02:11<00:00,  1.56it/s, v_num=55, lr=5e-5, train_student_loss=0.492, train_distillation_loss=19.70, train_loss=5.310, train_acc=95.80, train_acc_top5=100.0, val_student_loss=0.632, val_distillation_loss=19.70, val_loss=5.390, val_acc=94.50, val_acc_top5=99.10]\n"]}],"source":["teacher = torch.load('./_checkpoints/teacher/epoch_9.pth')\n","student = DeiTForImageClassification.from_pretrained('facebook/deit-base-distilled-patch16-224', num_labels=102)\n","\n","model_trainer = TrainerDistillation(teacher, student)\n","\n","trainer = pl.Trainer(\n","    max_epochs = 10,\n","    devices=1,\n","    accelerator='gpu',\n",")\n","trainer.fit(model_trainer, train_dataloader, valid_dataloader)"]},{"cell_type":"markdown","metadata":{},"source":["Creo mi propio modelo destilado a partir de quitarle la mitad de las capas a un ViT grande y completamente preentrenado "]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["class DistillViT(nn.Module):\n","    def __init__(self, vit_model, delete_weights=True):\n","        super(DistillViT, self).__init__()\n","        self.vit_model = vit_model\n","        if delete_weights:\n","            self.vit_model.apply(self.reset_parameters)\n","\n","        num_layers_to_remove = len(self.vit_model.vit.encoder.layer) // 2\n","        self.vit_model.vit.encoder.layer = self.vit_model.vit.encoder.layer[:num_layers_to_remove]\n","    \n","    def reset_parameters(self, layer):\n","        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n","            layer.reset_parameters()\n","\n","    def forward(self, x):\n","        x = self.vit_model(x)\n","        return x"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name          | Type             | Params\n","---------------------------------------------------\n","0 | net           | DistillViT       | 43.3 M\n","1 | train_metrics | MetricCollection | 0     \n","2 | val_metrics   | MetricCollection | 0     \n","---------------------------------------------------\n","78.4 K    Trainable params\n","43.3 M    Non-trainable params\n","43.3 M    Total params\n","173.399   Total estimated model params size (MB)\n"]},{"name":"stdout","output_type":"stream","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\vfont\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  rank_zero_warn(\n"]},{"name":"stdout","output_type":"stream","text":["                                                                           "]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\vfont\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  rank_zero_warn(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 0: 100%|██████████| 205/205 [00:54<00:00,  3.76it/s, v_num=65, lr=0.000529, train_loss=2.860, train_acc=54.20, train_acc_top5=79.20, val_loss=2.950, val_acc=40.70, val_acc_top5=75.10]\n","Epoch 1/10 val_loss: 3.0733 val_acc: 37.8596\n","Epoch 1: 100%|██████████| 205/205 [00:50<00:00,  4.08it/s, v_num=65, lr=5e-5, train_loss=2.410, train_acc=50.00, train_acc_top5=87.50, val_loss=2.670, val_acc=49.90, val_acc_top5=81.40]    \n","Epoch 2/10 val_loss: 2.6746 val_acc: 50.1603\n","Epoch 2: 100%|██████████| 205/205 [00:50<00:00,  4.06it/s, v_num=65, lr=0.000521, train_loss=2.010, train_acc=66.70, train_acc_top5=100.0, val_loss=2.440, val_acc=56.50, val_acc_top5=85.80]\n","Epoch 3/10 val_loss: 2.4438 val_acc: 56.7441\n","Epoch 3: 100%|██████████| 205/205 [00:50<00:00,  4.06it/s, v_num=65, lr=0.001, train_loss=1.730, train_acc=70.80, train_acc_top5=91.70, val_loss=1.830, val_acc=70.50, val_acc_top5=92.40]   \n","Epoch 4/10 val_loss: 1.8302 val_acc: 70.8467\n","Epoch 4: 100%|██████████| 205/205 [01:10<00:00,  2.89it/s, v_num=65, lr=0.000529, train_loss=1.640, train_acc=58.30, train_acc_top5=95.80, val_loss=1.470, val_acc=79.10, val_acc_top5=94.70]\n","Epoch 5/10 val_loss: 1.4706 val_acc: 79.2601\n","Epoch 5: 100%|██████████| 205/205 [00:51<00:00,  4.02it/s, v_num=65, lr=5e-5, train_loss=1.280, train_acc=75.00, train_acc_top5=87.50, val_loss=1.390, val_acc=81.30, val_acc_top5=95.50]    \n","Epoch 6/10 val_loss: 1.3955 val_acc: 81.3301\n","Epoch 6: 100%|██████████| 205/205 [00:50<00:00,  4.04it/s, v_num=65, lr=0.000521, train_loss=0.959, train_acc=91.70, train_acc_top5=100.0, val_loss=1.330, val_acc=81.10, val_acc_top5=95.70]\n","Epoch 7/10 val_loss: 1.3284 val_acc: 80.9963\n","Epoch 7: 100%|██████████| 205/205 [01:17<00:00,  2.63it/s, v_num=65, lr=0.001, train_loss=1.180, train_acc=79.20, train_acc_top5=91.70, val_loss=1.130, val_acc=83.70, val_acc_top5=96.10]   \n","Epoch 8/10 val_loss: 1.1306 val_acc: 83.9209\n","Epoch 8: 100%|██████████| 205/205 [00:50<00:00,  4.08it/s, v_num=65, lr=0.000529, train_loss=0.829, train_acc=91.70, train_acc_top5=100.0, val_loss=0.980, val_acc=85.60, val_acc_top5=97.20]\n","Epoch 9/10 val_loss: 0.9809 val_acc: 85.6303\n","Epoch 9: 100%|██████████| 205/205 [01:04<00:00,  3.18it/s, v_num=65, lr=5e-5, train_loss=0.903, train_acc=87.50, train_acc_top5=95.80, val_loss=0.951, val_acc=85.50, val_acc_top5=96.80]    \n","Epoch 10/10 val_loss: 0.9518 val_acc: 85.4167\n"]},{"name":"stderr","output_type":"stream","text":["`Trainer.fit` stopped: `max_epochs=10` reached.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9: 100%|██████████| 205/205 [01:05<00:00,  3.14it/s, v_num=65, lr=5e-5, train_loss=0.903, train_acc=87.50, train_acc_top5=95.80, val_loss=0.951, val_acc=85.50, val_acc_top5=96.80]\n"]}],"source":["vit = ViTForImageClassification.from_pretrained(\n","            'google/vit-base-patch16-224-in21k', \n","            num_labels=102\n","        )\n","distilled_vit = DistillViT(vit, delete_weights=False)\n","model_trainer = TrainerFineTune(distilled_vit)\n","\n","trainer = pl.Trainer(\n","    max_epochs = 10,\n","    devices=1,\n","    accelerator='gpu',\n",")\n","trainer.fit(model_trainer, train_dataloader, valid_dataloader)"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name          | Type                      | Params\n","------------------------------------------------------------\n","0 | teacher       | ViTForImageClassification | 85.9 M\n","1 | student       | DistillViT                | 43.3 M\n","2 | train_metrics | MetricCollection          | 0     \n","3 | val_metrics   | MetricCollection          | 0     \n","------------------------------------------------------------\n","78.4 K    Trainable params\n","129 M     Non-trainable params\n","129 M     Total params\n","516.908   Total estimated model params size (MB)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 0: 100%|██████████| 205/205 [01:42<00:00,  2.00it/s, v_num=68, lr=0.000529, train_student_loss=3.210, train_distillation_loss=15.50, train_loss=6.290, train_acc=33.30, train_acc_top5=54.20, val_student_loss=2.920, val_distillation_loss=15.00, val_loss=5.940, val_acc=38.30, val_acc_top5=72.00]\n","Epoch 1/10 val_loss: 6.0985 val_acc: 35.7639\n","Epoch 1: 100%|██████████| 205/205 [01:41<00:00,  2.03it/s, v_num=68, lr=5e-5, train_student_loss=2.480, train_distillation_loss=14.20, train_loss=5.400, train_acc=58.30, train_acc_top5=75.00, val_student_loss=2.650, val_distillation_loss=14.40, val_loss=5.570, val_acc=45.50, val_acc_top5=77.50]    \n","Epoch 2/10 val_loss: 5.5814 val_acc: 45.7399\n","Epoch 2: 100%|██████████| 205/205 [01:41<00:00,  2.02it/s, v_num=68, lr=0.000521, train_student_loss=1.930, train_distillation_loss=12.70, train_loss=4.620, train_acc=66.70, train_acc_top5=91.70, val_student_loss=2.410, val_distillation_loss=13.80, val_loss=5.250, val_acc=51.00, val_acc_top5=81.20]\n","Epoch 3/10 val_loss: 5.2543 val_acc: 51.2420\n","Epoch 3: 100%|██████████| 205/205 [01:41<00:00,  2.02it/s, v_num=68, lr=0.001, train_student_loss=1.580, train_distillation_loss=11.30, train_loss=4.010, train_acc=79.20, train_acc_top5=100.0, val_student_loss=1.790, val_distillation_loss=12.10, val_loss=4.350, val_acc=65.20, val_acc_top5=90.20]   \n","Epoch 4/10 val_loss: 4.3589 val_acc: 65.4647\n","Epoch 4: 100%|██████████| 205/205 [01:41<00:00,  2.01it/s, v_num=68, lr=0.000529, train_student_loss=1.490, train_distillation_loss=11.00, train_loss=3.870, train_acc=79.20, train_acc_top5=87.50, val_student_loss=1.410, val_distillation_loss=10.80, val_loss=3.760, val_acc=73.50, val_acc_top5=93.30]\n","Epoch 5/10 val_loss: 3.7649 val_acc: 73.7313\n","Epoch 5: 100%|██████████| 205/205 [01:42<00:00,  2.01it/s, v_num=68, lr=5e-5, train_student_loss=1.050, train_distillation_loss=10.20, train_loss=3.330, train_acc=91.70, train_acc_top5=100.0, val_student_loss=1.330, val_distillation_loss=10.60, val_loss=3.640, val_acc=75.70, val_acc_top5=94.50]    \n","Epoch 6/10 val_loss: 3.6423 val_acc: 75.8948\n","Epoch 6: 100%|██████████| 205/205 [01:42<00:00,  2.01it/s, v_num=68, lr=0.000521, train_student_loss=1.150, train_distillation_loss=9.990, train_loss=3.360, train_acc=83.30, train_acc_top5=100.0, val_student_loss=1.260, val_distillation_loss=10.30, val_loss=3.520, val_acc=76.20, val_acc_top5=94.40]\n","Epoch 7/10 val_loss: 3.5239 val_acc: 76.2821\n","Epoch 7: 100%|██████████| 205/205 [01:42<00:00,  2.00it/s, v_num=68, lr=0.001, train_student_loss=1.410, train_distillation_loss=10.60, train_loss=3.700, train_acc=75.00, train_acc_top5=83.30, val_student_loss=1.060, val_distillation_loss=9.470, val_loss=3.170, val_acc=80.20, val_acc_top5=95.60]   \n","Epoch 8/10 val_loss: 3.1708 val_acc: 80.3419\n","Epoch 8: 100%|██████████| 205/205 [01:42<00:00,  2.00it/s, v_num=68, lr=0.000529, train_student_loss=0.557, train_distillation_loss=8.240, train_loss=2.480, train_acc=100.0, train_acc_top5=100.0, val_student_loss=0.914, val_distillation_loss=8.820, val_loss=2.890, val_acc=82.60, val_acc_top5=96.10]\n","Epoch 9/10 val_loss: 2.8973 val_acc: 82.6522\n","Epoch 9: 100%|██████████| 205/205 [01:42<00:00,  2.01it/s, v_num=68, lr=5e-5, train_student_loss=0.667, train_distillation_loss=8.190, train_loss=2.550, train_acc=95.80, train_acc_top5=95.80, val_student_loss=0.886, val_distillation_loss=8.670, val_loss=2.830, val_acc=82.60, val_acc_top5=96.00]    \n","Epoch 10/10 val_loss: 2.8389 val_acc: 82.6522\n"]},{"name":"stderr","output_type":"stream","text":["`Trainer.fit` stopped: `max_epochs=10` reached.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9: 100%|██████████| 205/205 [01:44<00:00,  1.97it/s, v_num=68, lr=5e-5, train_student_loss=0.667, train_distillation_loss=8.190, train_loss=2.550, train_acc=95.80, train_acc_top5=95.80, val_student_loss=0.886, val_distillation_loss=8.670, val_loss=2.830, val_acc=82.60, val_acc_top5=96.00]\n"]}],"source":["teacher = torch.load('./_checkpoints/teacher/epoch_9.pth')\n","vit = ViTForImageClassification.from_pretrained(\n","            'google/vit-base-patch16-224-in21k', \n","            num_labels=102\n","        )\n","student = DistillViT(vit, delete_weights=False)\n","\n","model_trainer = TrainerDistillation(teacher, student)\n","\n","trainer = pl.Trainer(\n","    max_epochs = 10,\n","    devices=1,\n","    accelerator='gpu',\n",")\n","trainer.fit(model_trainer, train_dataloader, valid_dataloader)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"00b71d9f3b944a8388b0d8d47feaa833":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0137b2cdaf2149a3b59925550ec03160":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"02cd0144f9844747aa65d0e9d6f2b3fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08f580eb28114809af12a750c1cc89cf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bc55420944240619ea526578924072f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_945d974d5ea543bf84895b5147e617ed","max":205,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c093d9c835874013a7752d3c1c49e759","value":20}},"103ec964c7bb43cdadc57009c0537ef9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_99d377b675d7464e95ce27dd01c9ba41","placeholder":"​","style":"IPY_MODEL_8aa6e33847e043a59c67786fc99ec25a","value":" 2/2 [00:00&lt;00:00,  2.36it/s]"}},"163477237e964e5dab6f60674ce628a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25516d0870b94962acb5b2bb807b55a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"369bea5e2cfb48228b37c00beac9504b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bab01974cea44d80b8e237d74d77a222","IPY_MODEL_0bc55420944240619ea526578924072f","IPY_MODEL_a4d0f2fd487a468eaab129a1ea702db5"],"layout":"IPY_MODEL_c7db01aa60534c4e958668d78ce8aefb"}},"3c291dbc8b59422a967e4a7a58ca4fe6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d0009b68f1540de862eaf9006d86a1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2a6162d81154b1aaa85472da92aa3e2","placeholder":"​","style":"IPY_MODEL_d5699c79b5ae4116a663fcf6967d5f72","value":"Epoch 0:   0%"}},"45715159d91143b5bce8eb8358b24110":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"4da79c41190246b4a95605a48e5fc95f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"578278203b3c456fb8265694876ad0c3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59a77a6345524dcf941c70967bfc9a2d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"61aafa86423543f688b7c6c5198523d7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"69b2375161a74dc2bbe6e5577b9f4cda":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7fe6cbf186f94d57a68253c1706f2580","IPY_MODEL_6b8edf26a2fa4166b1ba23018c949dda","IPY_MODEL_103ec964c7bb43cdadc57009c0537ef9"],"layout":"IPY_MODEL_59a77a6345524dcf941c70967bfc9a2d"}},"6acef49819c14a44b119859ad69d65e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c291dbc8b59422a967e4a7a58ca4fe6","max":103,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b5ac523ca8cb4605bbaaa6f9deb0b0fb","value":0}},"6b8edf26a2fa4166b1ba23018c949dda":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b62d8e70d1840cea2c8e56ddc182ab0","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_61aafa86423543f688b7c6c5198523d7","value":2}},"6ff625bf64204ae4a9473fcb05d28be1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f653b3c2960e4ad68c1095950a64eab4","placeholder":"​","style":"IPY_MODEL_00b71d9f3b944a8388b0d8d47feaa833","value":" 0/103 [00:00&lt;?, ?it/s]"}},"76f431f9c75b4349bac9634420d695f2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b62d8e70d1840cea2c8e56ddc182ab0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d46d0e82ad440bfbd4b78e68bb06bf4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3d0009b68f1540de862eaf9006d86a1b","IPY_MODEL_6acef49819c14a44b119859ad69d65e2","IPY_MODEL_6ff625bf64204ae4a9473fcb05d28be1"],"layout":"IPY_MODEL_45715159d91143b5bce8eb8358b24110"}},"7fe6cbf186f94d57a68253c1706f2580":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a93d0b0ab66f4b20a119572d9d710612","placeholder":"​","style":"IPY_MODEL_02cd0144f9844747aa65d0e9d6f2b3fb","value":"Sanity Checking DataLoader 0: 100%"}},"8aa6e33847e043a59c67786fc99ec25a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8ee92f1f0f6a43d487c98359bfb1aa3b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f79ff0f1b2d54ec59e6a5e64c87ca244","IPY_MODEL_e053e0383a254af0bb97d97886aef3ef","IPY_MODEL_d4360290a2c944b6825bc0b219d3f75c"],"layout":"IPY_MODEL_0137b2cdaf2149a3b59925550ec03160"}},"945d974d5ea543bf84895b5147e617ed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99d377b675d7464e95ce27dd01c9ba41":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4d0f2fd487a468eaab129a1ea702db5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7610b7b3b6348699abc461fa7847aed","placeholder":"​","style":"IPY_MODEL_4da79c41190246b4a95605a48e5fc95f","value":" 20/205 [03:45&lt;34:46,  0.09it/s, v_num=8, lr=0.00996, train_loss=-1.2e+3, train_acc=0.000, train_acc_top5=0.000]"}},"a93d0b0ab66f4b20a119572d9d710612":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5ac523ca8cb4605bbaaa6f9deb0b0fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bab01974cea44d80b8e237d74d77a222":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_578278203b3c456fb8265694876ad0c3","placeholder":"​","style":"IPY_MODEL_25516d0870b94962acb5b2bb807b55a7","value":"Epoch 0:  10%"}},"c093d9c835874013a7752d3c1c49e759":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c699e55d5ceb4d8f95d602bb713876c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c7db01aa60534c4e958668d78ce8aefb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"d0586697473e40f985a22623c5c9ed0a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d4360290a2c944b6825bc0b219d3f75c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfcd669fe4964b10911ca068a388a7df","placeholder":"​","style":"IPY_MODEL_163477237e964e5dab6f60674ce628a6","value":" 2/2 [00:24&lt;00:00,  0.08it/s]"}},"d5699c79b5ae4116a663fcf6967d5f72":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dfcd669fe4964b10911ca068a388a7df":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e053e0383a254af0bb97d97886aef3ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_76f431f9c75b4349bac9634420d695f2","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c699e55d5ceb4d8f95d602bb713876c0","value":2}},"e2a6162d81154b1aaa85472da92aa3e2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f653b3c2960e4ad68c1095950a64eab4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7610b7b3b6348699abc461fa7847aed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f79ff0f1b2d54ec59e6a5e64c87ca244":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_08f580eb28114809af12a750c1cc89cf","placeholder":"​","style":"IPY_MODEL_d0586697473e40f985a22623c5c9ed0a","value":"Sanity Checking DataLoader 0: 100%"}}}}},"nbformat":4,"nbformat_minor":0}
